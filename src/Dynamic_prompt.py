from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace
import streamlit as st
from dotenv import load_dotenv  
from langchain_core.prompts import PromptTemplate

load_dotenv()

llm = HuggingFaceEndpoint(
    repo_id="meta-llama/Llama-3.1-8B-Instruct",
    task="text-generation",
    temperature=0.8
)
model = ChatHuggingFace(llm = llm)

st.header("Research Tool")

paper_input = st.selectbox("Select Research Paper Name",["Attention Is All You Need",
                "BERT : Pre-Training of Deep Bidirectional Transformer","GPT-3 Language models are Few-Shot Learners",
                "Diffusion Models Beat GANs on Image Synthesis"])

style_input = st.selectbox("Select Explanation Style",["Beginer-Friendly",
                "Technical","Code-Oriented","Mathematical"])

length_input = st.selectbox("Select Explanation Length",["Short(1-2 paragraphs)","Medium(3-5 paragraphs)","Long(Detaiiled Explanation)"])

# Template 
template = PromptTemplate(
    template="""Please summarize the research paper titled "{paper_input}" with the following
specifications:
Explanation Style: {style_input}
Explanation Length: {length_input}
1. Mathematical Details:
- Include relevant mathematical equations if present in the paper.
- Explain the mathematical concepts using simple, intuitive code snippets
where applicable.
2. Analogies:
- Use relatable analogies to simplify complex ideas.
If certain information is not available in the paper, respond with: "Insufficient
information available" instead of guessing.
Ensure the summary is clear, accurate, and aligned with the provided style and
length. """,
input_variables=["paper_input",'style_input','length_input']
)

# Fill the placeholders
prompt = template.invoke({
    'paper_input':paper_input,
    'style_input':style_input,
    "length_input":length_input
})

if st.button("Semmarize"):
    result = model.invoke(prompt)
    st.write(result.content)